include: "../snakemake/conf_submission.sk"

# ==========================================================================
#                             EGAsubmitter
# ==========================================================================
# This file is part of EGAsubmitter.
#
# EGAsubmitter is Free Software: you can redistribute it and/or modify it
# under the terms found in the LICENSE.rst file distributed
# together with this file.
#
# EGAsubmitter is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
#
# ==========================================================================
# Author: Marco Viviani <marco.viviani@ircc.it>
# ==========================================================================
#                           Snakefile_submission
# This is the main snakemake pipeline of EGAsubmitter; here there are all
# the processes that create the needed files, link them together where
# needed and submit to the user's EGA account
# ==========================================================================

### --------Preparation part-------- ###
# Following the structure of encrypt/upload we've left a single empty .done file/PHONY here at the end of the pipeline for
# clarity to all users, while all rule chaining internal to the pipeline are now based only on "real" output files.
rule all:
    input: IDS+"/DatasetID"
    output: DONE+"/AllSubmissions.done"
    shell:
        """
            echo "All done:
            Please, check on the web page
            https://ega-archive.org/submitter-portal/#/login
            if everything is fine, you shall proceed with the validation"
            touch {output}
        """
### Converts all the yaml files given by the user: the user must place all the files in the yaml/ folder, after filling them out
rule yamlConversion:
    input: yaml=ancient(USER_METADATA+"/yaml/{what}.yaml") ###itera sui campi dello yaml, se è un numero, apri il txt corrispondente e vedere che sia nel range: se trovi numero ma non c'è il file corrispondete, passa
    output: json=USER_METADATA+"/json/{what}.json" 
    run:
        import os
        import ruamel.yaml
        import json 
        yaml = ruamel.yaml.YAML(typ='safe')
        with open(input.yaml) as yaml_in, open(output.json, "w") as json_out:
            yaml_object = yaml.load(yaml_in)
            json.dump(yaml_object, json_out, indent=1)

### This will build the Runs file, one for each sample: it depends on the encrypt-upload phase last generated file rather than using a subworkflow or other more
### snakemake specific ways of linking snakefiles to be more clear to all users (and to ease remote debugging).
checkpoint buildRuns:
    input: doneYaml=expand(USER_METADATA+"/json/{what}.json", what=FILES), encrypted=ancient(TRANSFER+"/logs/done/encrypted-upload.done")
    output: csv=SAMPLES_PATH+"/SamplesInformation.csv", samples=SAMPLES_PATH+"/Allfiles_list.txt", runs=RUNS_PATH+"/Allfiles_list.txt", allsamples=USER_METADATA+"/AllSamples_list.txt", desc=USER_METADATA+"/description", title=USER_METADATA+"/title"
    params: tool=SRC_DIR+"/buildRuns.py", path=DATASET, runType=FILETYPE, plate=TEMPLATE
    shell:
        """ 
            python3 {params.tool} -o {output.csv} -p {params.path} -t {params.runType} -j {params.plate}
        """ 

rule samples:
    input: csv=SAMPLES_PATH+"/SamplesInformation.csv"
    output: json=SAMPLES_PATH+"/{sample}.json"
    run:
        import json
        import csv
        primary_fields = ['alias', 'title', 'description', 'caseOrControlId', 'genderId',
        'organismPart', 'cellLine', 'region', 'phenotype', 'subjectId', 'anonymizedName', 'bioSampleId', 'sampleAge',
        'sampleDetail']
        with open(input.csv) as csv_file:
            reader = csv.DictReader(csv_file, skipinitialspace=True, delimiter=",")
            for row in reader:
                sample = row['alias']
                # Since this rule will be called once for all the samples it stops as soon as it finds the right wildcard
                # (sample corrisponding to one of the rows in SamplesInformation.csv)
                # and generate its json
                if sample == wildcards.sample:
                    d = {k: v for k, v in row.items() if k in primary_fields}
                    d['attributes'] = [{'tag': row['attributes.tag'], 'value': row['attributes.value']}]
                    jsonString = json.dumps(d, indent=2)
                    jsonFile = open(SAMPLES_PATH+"/"+sample+".json", "w")
                    jsonFile.write(jsonString)
                    jsonFile.close()

# desc/title will ensure that buildRuns have run, getJson is a function that will produce (if the checkpoint has run) all the path to json files with metadata for each sample (created by the rule samples).
rule sub:
    input: getJson, json=ancient(DATA+"/SubmissionSubsetTemplate.json"), desc=USER_METADATA+"/description", title=USER_METADATA+"/title"
    output: submission=SUBMISSION_PATH+"/Submission.json"
    params: path=DATASET
    run:
        import json
        
        with open(input.title) as t, open(input.desc) as d, open(input.json, 'r') as file:
            title = t.readline().strip()
            desc = d.readline().strip()
            df = json.load(file)
            df['title'] = title
            df['description'] = desc
        with open(output.submission, 'w') as sub:
            json.dump(df, sub, indent=2)
### --------Preparation part-------- ###

### --------Submission.json part-------- ###

### With this first submission we start the process and get the submission ID from EGA
rule submission:
    input: token=ancient("dataset/SessionToken"), json=SUBMISSION_PATH+"/Submission.json" ### This is the submission file with only title and description
    params: path=EGA_URL+"/submissions", idbckup=IDBCKUP
    output: id=SUBMISSION_PATH+"/SubmissionID"
    log: SUB_LOGS+"/Submission_info.log",
    shell:
        """
            token=$(cat {input.token})
            curl -H "Content-type: application/json" -H "X-Token: $token" -X POST {params.path} -d @{input.json} > {log}
            jq -r '.response.result[0].id' {log} > {output.id}
            error=($(jq -r '.header.errorCode' {log}))
            if [ "$error" -ne 1 ]; then
                echo "Submission of Submission.json failed. The reason probably is:"
                jq -r '.header.userMessage' {log}
                exit 1
            fi
            now=$(date +"%d_%m_%Y")
            cp {output.id} {output.id}_$now
            mv {output.id}_$now {params.idbckup}
            echo "Submission ID has been saved in {params.idbckup}"
            echo "Submission.json has been submitted"
        """

### STUDY ###
rule study:
    input: token=ancient("dataset/SessionToken"), json=USER_METADATA+"/json/Study.json", id=SUBMISSION_PATH+"/SubmissionID"
    params: path=EGA_URL
    output: id=IDS+"/StudyID"
    log: SUB_LOGS+"/Study_submission.log"
    shell:
        """ 
            token=$(cat {input.token})
            path={params.path}/submissions/$(cat {input.id})/studies
            curl -H "Content-type: application/json" -H "X-Token: $token" -X POST $path -d @{input.json} > {log}
            jq -r '.response.result[0].id' {log} > {output.id}
            error=($(jq -r '.header.errorCode' {log}))
            if [ "$error" -ne 1 ]; then
                echo "Submission of Study.json failed. The reason probably is:"
                jq -r '.header.userMessage' {log}
                exit 1
            fi
            echo "Study.json has been submitted"
        """
### --- ###

### SAMPLES ###
rule samplesSubmission:
    input: token=ancient("dataset/SessionToken"), json=SAMPLES_PATH+"/{sample}.json", id=SUBMISSION_PATH+"/SubmissionID"
    params: path=EGA_URL
    output: id=SAMPLES_PATH+"/IDs/{sample}_ID"
    log: SUB_LOGS+"/samples/{sample}.log"
    shell:
        """
            token=$(cat {input.token})
            path={params.path}/submissions/$(cat {input.id})/samples
            curl -H "Content-type: application/json" -H "X-Token: $token" -X POST $path -d @{input.json} > {log}
            jq -r '.response.result[0].id' {log} > {output.id}
            error=($(jq -r '.header.errorCode' {log}))
            if [ "$error" -ne 1 ]; then
                echo "Submission of {wildcards.sample}.json failed. The reason probably is:"
                jq -r '.header.userMessage' {log}
                exit 1
            fi
            echo "{wildcards.sample}.json has been submitted"
        """
### --- ###

### EXPERIMENT ###
### Here the tool recover the Study ID (submitted before) and link it to the experiment
rule experimentAlias:
    input: getSample, json=ancient(USER_METADATA+"/json/Experiment.json"), idStudy=IDS+"/StudyID"
    output: after=SUBMISSION_PATH+"/Experiment.json"
    run:
        import json
        with open(input.idStudy) as i:
            id = i.readline().strip()
        with open(input.json) as file:
            df = json.load(file)
            df['studyId'] = id
        with open(output.after, 'w') as json_file:
            json.dump(df, json_file, indent=2)

rule experimentSubmission:
    input: token=ancient("dataset/SessionToken"), json=SUBMISSION_PATH+"/Experiment.json", id=SUBMISSION_PATH+"/SubmissionID"
    params: path=EGA_URL
    output: id=SUBMISSION_PATH+"/IDs/Experiment_ID"
    log: SUB_LOGS+"/experimentSubmission.log"
    shell:
        """ 
            token=$(cat {input.token})
            path={params.path}/submissions/$(cat {input.id})/experiments
            curl -H "Content-type: application/json" -H "X-Token: $token" -X POST $path -d @{input.json} > {log}
            jq -r '.response.result[0].id' {log} > {output.id}
            error=($(jq -r '.header.errorCode' {log}))
            if [ "$error" -ne 1 ]; then
                echo "Submission of Study.json failed. The reason probably is:"
                jq -r '.header.userMessage' {log}
                exit 1
            fi
            echo "Experiment.json has been submitted"
        """
### --- ###

### RUNS ###
### Here the tool recover the Experiment ID and Samples IDs (submitted before) and link them to the Runs;
### Each Sample ID is linked to its specific Run file
rule runsAlias:
    input: getSample, json=ancient(RUNS_PATH+"/Run_{sample}.json"), idExp=SUBMISSION_PATH+"/IDs/Experiment_ID", idSample=SAMPLES_PATH+"/IDs/{sample}_ID"
    output: after=SUBMISSION_PATH+"/runs/Run_{sample}.json"
    run:
        import json
        with open(input.idExp) as i, open(input.idSample) as s:
            id = i.readline().strip()
            sample = s.readline().strip()
        with open(input.json) as file:
            df = json.load(file)
            df['experimentId'] = id
            df['sampleId'] = sample
        with open(output.after, 'w') as json_file:
            json.dump(df, json_file, indent=2)

rule runsSubmission:
    input: token=ancient('dataset/SessionToken'), json=SUBMISSION_PATH+"/runs/Run_{sample}.json", id=SUBMISSION_PATH+"/SubmissionID"
    params: path=EGA_URL
    output: id=RUNS_PATH+"/IDs/Run_{sample}_ID"
    log: SUB_LOGS+"/runs/Run_{sample}.log"
    shell:
        """
            token=$(cat {input.token})
            path={params.path}/submissions/$(cat {input.id})/runs
            curl -H "Content-type: application/json" -H "X-Token: $token" -X POST $path -d @{input.json} > {log}
            jq -r '.response.result[0].id' {log} > {output.id}
            error=($(jq -r '.header.errorCode' {log}))
            if [ "$error" -ne 1 ]; then
                echo "Submission of Run_{wildcards.sample}.json failed. The reason probably is:"
                jq -r '.header.userMessage' {log}
                exit 1
            fi
            echo "Run_{wildcards.sample}.json has been submitted"
        """
### --- ###

### DAC & Policy ###
rule dac:
    input: getRun, token=ancient('dataset/SessionToken'), json=USER_METADATA+"/json/DAC.json", id=SUBMISSION_PATH+"/SubmissionID"
    params: path=EGA_URL
    output: id=IDS+"/DACID"
    log: SUB_LOGS+"/DAC_submission.log"
    shell:
        """ 
            token=$(cat {input.token})
            path={params.path}/submissions/$(cat {input.id})/dacs
            curl -H "Content-type: application/json" -H "X-Token: $token" -X POST $path -d @{input.json} > {log}
            jq -r '.response.result[0].id' {log} > {output.id}
            error=($(jq -r '.header.errorCode' {log}))
            if [ "$error" -ne 1 ]; then
                echo "DAC upload failed. The reason probably is:"
                jq -r '.header.userMessage' {log}
                exit 1
            fi
            echo "DAC.json has been submitted"
        """

### Here the tool recover the DAC ID (submitted before) and link it to the policy
rule policyAlias:
    input: json=ancient(USER_METADATA+"/json/Policy.json"), idDAC=IDS+"/DACID"
    output: after=SUBMISSION_PATH+"/Policy.json"
    run:
        import json
        with open(input.idDAC) as i:
            id = i.readline().strip()
        with open(input.json) as file:
            df = json.load(file)
            df['dacId'] = id
        with open(output.after, 'w') as json_file:
            json.dump(df, json_file, indent=2)

rule policy:
    input: token=ancient('dataset/SessionToken'), json=SUBMISSION_PATH+"/Policy.json", id=SUBMISSION_PATH+"/SubmissionID"
    params: path=EGA_URL
    output: id=IDS+"/PolicyID"
    log: SUB_LOGS+"/Policy_submission.log"
    shell:
        """ 
            token=$(cat {input.token})
            path={params.path}/submissions/$(cat {input.id})/policies
            curl -H "Content-type: application/json" -H "X-Token: $token" -X POST $path -d @{input.json} > {log}
            jq -r '.response.result[0].id' {log} > {output.id}
            error=($(jq -r '.header.errorCode' {log}))
            if [ "$error" -ne 1 ]; then
                echo "Policy upload failed. The reason probably is:"
                jq -r '.header.userMessage' {log}
                exit 1
            fi
            echo "Policy.json has been submitted"
        """
### --- ###

### DATASET ###
### Lastly, EGAsubmitter links everything in the Dataset.json
rule datasetAlias:
    input: json=ancient(USER_METADATA+"/json/Dataset.json"), idPolicy=IDS+"/PolicyID"
    params: runIDpath=ancient(RUNS_PATH+"/IDs/")
    output: after=SUBMISSION_PATH+"/Dataset.json"
    run:
        import json
        import os
        with open(input.json) as file:
            df = json.load(file)
        file = os.listdir(params.runIDpath)
        for filename in file:
            if filename.endswith("_ID"):
                with open(os.path.join(params.runIDpath, filename), 'r') as f:
                    runID = f.readline().strip()
                    df['runsReferences'].append(runID)
        with open(input.idPolicy) as i:
            id = i.readline().strip()
            df['policyId'] = id
        with open(output.after, 'w') as json_file:
            json.dump(df, json_file, indent=2)

rule dataset:
    input: token=ancient('dataset/SessionToken'), json=SUBMISSION_PATH+"/Dataset.json", id=SUBMISSION_PATH+"/SubmissionID"
    params: path=EGA_URL
    output: id=IDS+"/DatasetID"
    log: SUB_LOGS+"/Dataset_submission.log"
    shell:
        """ 
            token=$(cat {input.token})
            path={params.path}/submissions/$(cat {input.id})/datasets
            curl -H "Content-type: application/json" -H "X-Token: $token" -X POST $path -d @{input.json} > {log}
            jq -r '.response.result[0].id' {log} > {output.id}
            error=($(jq -r '.header.errorCode' {log}))
            if [ "$error" -ne 1 ]; then
                echo "Dataset upload failed. The reason probably is:"
                jq -r '.header.userMessage' {log}
                exit 1
            fi
            echo "Dataset.json has been submitted"
        """
### --- ###
### --------Submission part-------- ###
